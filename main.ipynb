{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import spektral  # for preprocessing the cora dataset\n",
    "from spektral.data.loaders import SingleLoader\n",
    "from spektral.layers import GCNConv\n",
    "from spektral.models.gcn import GCN\n",
    "from spektral.transforms import LayerPreprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing node features\n",
      "nodes: 2708, node_features: 1433\n",
      "classes: 7\n",
      "training nodes: 140, testing nodes: 1000, validation nodes: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nilec\\Venvs\\ds\\lib\\site-packages\\scipy\\sparse\\_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset = spektral.datasets.citation.Citation(name=\"cora\", normalize_x=True, transforms=[LayerPreprocess(GCNConv)])\n",
    "# dataset information\n",
    "print(\"nodes: {}, node_features: {}\".format(dataset.n_nodes, dataset.n_node_features))\n",
    "print(\"classes: {}\".format(dataset.n_labels))\n",
    "mask_tr = dataset.mask_tr\n",
    "mask_te = dataset.mask_te\n",
    "mask_va = dataset.mask_va\n",
    "print(\"training nodes: {}, testing nodes: {}, validation nodes: {}\".format(np.count_nonzero(mask_tr == True), \n",
    "                                                                           np.count_nonzero(mask_te == True), \n",
    "                                                                           np.count_nonzero(mask_va == True)))\n",
    "# adjacency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spektral.data.loaders.SingleLoader at 0x1437b493df0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the masks into normalized scalars\n",
    "weights_tr, weights_te, weights_va = (\n",
    "    mask.astype('float32') / np.count_nonzero(mask) for mask in (mask_tr, mask_te, mask_va)\n",
    ")\n",
    "\n",
    "# Build the GCN model\n",
    "model = GCN(n_labels=dataset.n_labels)\n",
    "model.compile(\n",
    "    optimizer = Adam(),\n",
    "    loss=CategoricalCrossentropy(reduction=\"sum\"),\n",
    "    weighted_metrics=[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: (((2708, 1433), (2708, 2708)), (2708, 7), (2708,)), types: ((tf.float32, tf.float32), tf.float32, tf.bool)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "loaded_tr = SingleLoader(dataset=dataset, sample_weights=weights_tr)\n",
    "loaded_te = SingleLoader(dataset=dataset, sample_weights=weights_te)\n",
    "loaded_va = SingleLoader(dataset=dataset, sample_weights=weights_va)\n",
    "\n",
    "lr = 1e-2\n",
    "seed = 0\n",
    "epochs = 200\n",
    "patience = 10\n",
    "data = \"core\"\n",
    "\n",
    "model.fit(\n",
    "    loaded_tr.load(),\n",
    "    steps_per_epoch=loaded_tr.steps_per_epoch,\n",
    "    validation_data=loaded_va.load(),\n",
    "    validation_steps=loaded_va.steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "results = model.evaluate(loaded_te.load(), steps=loaded_te.steps_per_epoch)\n",
    "print(\"Test loss: {}\\n\" \"Test accuracy: {}\".format(*results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c17fe89368f3df3b6fd3fdfd57958e43f86c5fba66a270cb992506caf886a193"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
